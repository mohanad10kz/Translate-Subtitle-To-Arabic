import os
import time
import json
import sys
import re
from pathlib import Path
import webvtt
import pysrt
from tqdm import tqdm
from openai import OpenAI
from dotenv import load_dotenv

# 2. ÿ™ÿ≠ŸÖŸäŸÑ ÿßŸÑŸÖÿ™ÿ∫Ÿäÿ±ÿßÿ™ ŸÖŸÜ ŸÖŸÑŸÅ .env
load_dotenv()

# ==========================================
# 1. ÿ•ÿπÿØÿßÿØÿßÿ™ OpenRouter
# ==========================================
# 3. ŸÇÿ±ÿßÿ°ÿ© ÿßŸÑŸÖŸÅÿ™ÿßÿ≠ ÿ®ÿ£ŸÖÿßŸÜ
API_KEY = os.getenv("API_KEY")

# ÿßŸÑÿ™ÿ≠ŸÇŸÇ ŸÖŸÜ ÿ£ŸÜ ÿßŸÑŸÖŸÅÿ™ÿßÿ≠ ÿ™ŸÖ ÿ™ÿ≠ŸÖŸäŸÑŸá
if not API_KEY:
    print("‚ùå Error: Could not find 'API_KEY' in .env file.")
    print("üí° Please create a .env file and add your key.")
    sys.exit(1)

# ÿßÿ≥ŸÖ ÿßŸÑŸÖŸàÿØŸäŸÑ
# MODEL_NAME = "google/gemini-2.0-flash-exp:free"
MODEL_NAME = "xiaomi/mimo-v2-flash:free"
# MODEL_NAME = "deepseek/deepseek-r1-0528:free"

client = OpenAI(
    base_url="https://openrouter.ai/api/v1",
    api_key=API_KEY,
)

SYSTEM_PROMPT = """
You are a Senior Technical Translator and Software Engineering Instructor for Arab developers.
Your task is to translate a list of subtitle lines from English to Arabic, specifically for a programming course.

### üéØ OBJECTIVE:
Produce a translation that sounds natural to an Arab developer (Tech-Savvy Arabic). Do not use stiff, academic, or "Google Translate" style Arabic.

### ‚ö†Ô∏è CRITICAL TECHNICAL RULES (ZERO TOLERANCE):
1. **JSON Only:** Return NOTHING but a raw JSON list of strings. No Markdown code blocks (```json), no intro text, no explanations.
2. **Line Count:** If I send N lines, you MUST return exactly N lines. Never merge or split lines.
3. **Code Preservation:** NEVER translate code syntax, variable names, function names, file paths, or CLI commands.
   - ‚ùå Bad: "ÿ≥ÿ¨ŸÑ ÿØŸàÿ™ ŸÑŸàÿ¨"
   - ‚úÖ Good: "console.log"
   - ‚ùå Bad: "ÿßŸÑŸÖÿ™ÿ∫Ÿäÿ± ŸÖÿ≥ÿ™ÿÆÿØŸÖ"
   - ‚úÖ Good: "user variable"

### üó£Ô∏è TRANSLATION STYLE GUIDE:
1. **Keep Tech Terms English:** Do not translate standard technical terms. Keep them in English.
   - ‚ùå Bad: "Ÿàÿßÿ¨Ÿáÿ© ÿ®ÿ±ŸÖÿ¨ÿ© ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇÿßÿ™", "ÿ•ÿ∑ÿßÿ± ÿßŸÑÿπŸÖŸÑ", "ÿßŸÑŸÖŸÉŸàŸÜ", "ÿßŸÑÿÆŸÑŸÅŸäÿ©"
   - ‚úÖ Good: "API", "Framework", "Component", "Backend"
2. **Natural Flow:** Use "Arabizi-style" technical phrasing common in the industry.
   - ‚ùå Bad: "ÿ≥ŸàŸÅ ŸÜŸÇŸàŸÖ ÿ®ÿ•ŸÜÿ¥ÿßÿ° ŸÖÿ´ŸäŸÑ ÿ¨ÿØŸäÿØ ŸÖŸÜ ÿßŸÑŸÅÿ¶ÿ©"
   - ‚úÖ Good: "ÿ≥ŸÜŸÇŸàŸÖ ÿ®ÿ•ŸÜÿ¥ÿßÿ° Instance ÿ¨ÿØŸäÿØ ŸÖŸÜ ÿßŸÑŸÄ Class"
3. **Short Lines:** If a line is very short (1-3 words) and is a label or title (e.g., "Introduction", "Chapter 1", "Next.js"), translate it ONLY if it makes sense. If it's a pure tech term like "React Hooks", keep it English.

### üìù EXAMPLES (Follow this pattern):

**Input:**
[
  "Welcome back to the course.",
  "In this lecture, we will look at the useEffect hook.",
  "It allows us to handle side effects.",
  "const data = await fetch('/api/user');",
  "So, let's dive into the code."
]

**Output:**
[
  "ÿ£ŸáŸÑÿßŸã ÿ®ŸÉŸÖ ŸÖÿ¨ÿØÿØÿßŸã ŸÅŸä ÿßŸÑŸÉŸàÿ±ÿ≥.",
  "ŸÅŸä Ÿáÿ∞Ÿá ÿßŸÑŸÖÿ≠ÿßÿ∂ÿ±ÿ©ÿå ÿ≥ŸÜŸÑŸÇŸä ŸÜÿ∏ÿ±ÿ© ÿπŸÑŸâ ÿßŸÑŸÄ useEffect hook.",
  "ÿ•ŸÜŸá Ÿäÿ≥ŸÖÿ≠ ŸÑŸÜÿß ÿ®ÿßŸÑÿ™ÿπÿßŸÖŸÑ ŸÖÿπ ÿßŸÑŸÄ side effects.",
  "const data = await fetch('/api/user');",
  "ÿ•ÿ∞Ÿãÿßÿå ÿØÿπŸàŸÜÿß ŸÜÿ∫Ÿàÿµ ŸÅŸä ÿßŸÑŸÉŸàÿØ."
]

### üö® FINAL WARNING:
- Do NOT output English lines for sentences (e.g., "So then..." must become "ÿ•ÿ∞Ÿãÿß ÿ®ÿπÿØ ÿ∞ŸÑŸÉ...").
- Only keep English if it is Code, a Tech Term, or a Proper Noun.
"""

RLE = '\u202b'
PDF = '\u202c'

# ==========================================
# ÿØŸàÿßŸÑ ŸÖÿ≥ÿßÿπÿØÿ© (Utils)
# ==========================================
def extract_json_list(text):
    """ ÿßÿ≥ÿ™ÿÆÿ±ÿßÿ¨ JSON ŸÖŸÜ ÿßŸÑŸÜÿµ """
    try:
        start = text.find('[')
        end = text.rfind(']')
        if start != -1 and end != -1:
            clean_json = text[start:end+1]
            return json.loads(clean_json)
        return json.loads(text)
    except:
        return None

def has_arabic(text):
    """ ŸÅÿ≠ÿµ ŸáŸÑ Ÿäÿ≠ÿ™ŸàŸä ÿßŸÑŸÜÿµ ÿπŸÑŸâ ÿ≠ÿ±ŸàŸÅ ÿπÿ±ÿ®Ÿäÿ© """
    return bool(re.search(r'[\u0600-\u06FF]', text))

def is_output_file(file_path):
    """ ŸÅÿ≠ÿµ ŸáŸÑ ÿßŸÑŸÖŸÑŸÅ Ÿäÿ≠ÿ™ŸàŸä ÿπŸÑŸâ ÿπŸÑÿßŸÖÿßÿ™ RTL (ÿπÿ±ÿ®Ÿä) """
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            head = f.read(1000)
            if "direction: rtl" in head or "text-align: right" in head or "align:right" in head:
                return True
            # ŸÅÿ≠ÿµ ÿ•ÿ∂ÿßŸÅŸä ŸÑŸÖÿ≠ÿ™ŸàŸâ ÿßŸÑÿ≥ÿ∑Ÿàÿ± ŸÅŸä ÿ≠ÿßŸÑÿ© ÿπÿØŸÖ Ÿàÿ¨ŸàÿØ ÿßŸÑŸáŸäÿØÿ±
            if has_arabic(head):
                return True
    except:
        pass
    return False

# ==========================================
# ŸÖŸÜÿ∑ŸÇ ÿßŸÑÿ™ÿ±ÿ¨ŸÖÿ© ŸàÿßŸÑÿ™ÿ≠ŸÇŸÇ
# ==========================================
def is_valid_translation(original_batch, translated_batch):
    """
    ÿØÿßŸÑÿ© ÿßŸÑÿ™ÿ≠ŸÇŸÇ ÿßŸÑÿ∞ŸÉŸäÿ©: ÿ™ŸÖŸäÿ≤ ÿ®ŸäŸÜ ÿßŸÑŸÖÿµÿ∑ŸÑÿ≠ÿßÿ™ ÿßŸÑÿ™ŸÇŸÜŸäÿ© (ÿßŸÑŸÖŸÇÿ®ŸàŸÑÿ© ÿ®ÿßŸÑÿ•ŸÜÿ¨ŸÑŸäÿ≤Ÿäÿ©)
    Ÿàÿ®ŸäŸÜ ÿßŸÑÿ¨ŸÖŸÑ ÿßŸÑÿ™Ÿä ŸÅÿ¥ŸÑ ÿßŸÑŸÖŸàÿØŸäŸÑ ŸÅŸä ÿ™ÿ±ÿ¨ŸÖÿ™Ÿáÿß.
    """
    if len(original_batch) != len(translated_batch):
        return False, "Mismatch length"

    echo_count = 0
    no_arabic_count = 0
    
    for org, trans in zip(original_batch, translated_batch):
        org_clean = org.strip()
        trans_clean = trans.strip()
        
        # 1. ŸÅÿ≠ÿµ ÿßŸÑÿ™ÿ∑ÿßÿ®ŸÇ (Echoing)
        # ŸÜÿ™ÿ¨ÿßŸáŸÑ ÿßŸÑÿ£ÿ≥ÿ∑ÿ± ÿßŸÑŸÇÿµŸäÿ±ÿ© ÿ¨ÿØÿßŸã (ÿ£ŸÇŸÑ ŸÖŸÜ 4 ŸÉŸÑŸÖÿßÿ™) ŸÑÿ£ŸÜ "React" ÿ™ÿ™ÿ±ÿ¨ŸÖ "React" ŸàŸáÿ∞ÿß ÿµÿ≠Ÿäÿ≠
        word_count = len(trans_clean.split())
        
        if word_count > 3 and org_clean.lower() == trans_clean.lower():
            echo_count += 1
            
        # 2. ŸÅÿ≠ÿµ ÿßŸÑŸÖÿ≠ÿ™ŸàŸâ ÿßŸÑÿπÿ±ÿ®Ÿä (Arabic Content Check)
        is_code_like = re.search(r'[{}();=><]', trans_clean) or trans_clean.startswith(('import ', 'console.', '<', 'return', 'export'))
        has_ar = has_arabic(trans_clean)
        
        # ÿßŸÑŸÑÿ∫ÿ≤ ŸáŸÜÿß: ŸÖÿ™Ÿâ ŸÜÿπÿ™ÿ®ÿ± ÿπÿØŸÖ Ÿàÿ¨ŸàÿØ ÿßŸÑÿπÿ±ÿ®Ÿäÿ© "ŸÖÿ¥ŸÉŸÑÿ©"ÿü
        # ŸÅŸÇÿ∑ ÿ•ÿ∞ÿß ŸÑŸÖ ŸäŸÉŸÜ ŸÉŸàÿØÿßŸã.. ŸàŸÉÿßŸÜ ÿßŸÑÿ≥ÿ∑ÿ± ÿ∑ŸàŸäŸÑÿßŸã (ÿ£ŸÉÿ´ÿ± ŸÖŸÜ 3 ŸÉŸÑŸÖÿßÿ™)
        if not is_code_like and not has_ar:
            if word_count > 3: 
                # ÿ¨ŸÖŸÑÿ© ÿ∑ŸàŸäŸÑÿ© ÿ•ŸÜÿ¨ŸÑŸäÿ≤Ÿäÿ©ÿü Ÿáÿ∞Ÿá ŸÖÿ¥ŸÉŸÑÿ©
                no_arabic_count += 1
            else:
                # ŸÉŸÑŸÖÿ© ÿ£Ÿà ŸÉŸÑŸÖÿ™ŸäŸÜ ÿ•ŸÜÿ¨ŸÑŸäÿ≤Ÿäÿ©ÿü (ŸÖÿ´ŸÑ "Chapter 1", "JSON Data", "React Hook")
                # Ÿáÿ∞ÿß ÿ∑ÿ®ŸäÿπŸä ŸÅŸä ÿßŸÑŸÉŸàÿ±ÿ≥ÿßÿ™ ÿßŸÑÿ™ŸÇŸÜŸäÿ©ÿå ŸÜÿ™ÿ¨ÿßŸáŸÑŸáÿß ŸàŸÑÿß ŸÜÿπÿØŸáÿß ÿÆÿ∑ÿ£
                pass

    # ÿßŸÑÿ™ÿ≥ÿßŸÖÿ≠ ŸÅŸä ŸÜÿ≥ÿ®ÿ© ÿßŸÑÿÆÿ∑ÿ£
    
    # ŸÜÿ±ŸÅÿ∂ ÿ•ÿ∞ÿß ŸÉÿßŸÜ ÿ£ŸÉÿ´ÿ± ŸÖŸÜ 30% ŸÖŸÜ ÿßŸÑÿ¨ŸÖŸÑ ÿßŸÑÿ∑ŸàŸäŸÑÿ© ŸÖŸÜÿ≥ŸàÿÆÿ© ÿ≠ÿ±ŸÅŸäÿßŸã
    if echo_count > (len(original_batch) * 0.3):
        return False, f"Too much echoing ({echo_count}/{len(original_batch)})"

    if no_arabic_count > (len(original_batch) * 0.4):
        return False, f"Missing Arabic ({no_arabic_count}/{len(original_batch)})"

    return True, "Valid"

def translate_batch(texts_batch, depth=0):
    """
    ÿ™ÿ±ÿ¨ŸÖÿ© ÿØŸÅÿπÿ© ŸÖÿπ ÿßÿ≥ÿ™ÿ±ÿßÿ™Ÿäÿ¨Ÿäÿ© 'ŸÅÿ±ŸÇ ÿ™ÿ≥ÿØ' + ÿßŸÑÿ™ÿ≠ŸÇŸÇ ŸÖŸÜ ÿßŸÑÿπÿ±Ÿàÿ®ÿ©
    """
    max_retries = 2
    user_message = f"Translate these specific {len(texts_batch)} lines to Arabic. Return exactly {len(texts_batch)} lines in a JSON list:"
    full_user_content = user_message + "\n" + json.dumps(texts_batch)

    for attempt in range(max_retries):
        try:
            messages = [
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": full_user_content}
            ]
            
            completion = client.chat.completions.create(
                model=MODEL_NAME,
                messages=messages,
                temperature=0.1 
            )
            
            response_text = completion.choices[0].message.content.strip()
            translated_list = extract_json_list(response_text)
            
            if translated_list is None:
                continue 

            # üî• ŸáŸÜÿß ÿßŸÑÿ•ÿ∂ÿßŸÅÿ© ÿßŸÑÿ¨ÿØŸäÿØÿ©: ÿßŸÑÿ™ÿ≠ŸÇŸÇ ŸÖŸÜ ÿµÿ≠ÿ© ÿßŸÑÿ™ÿ±ÿ¨ŸÖÿ©
            is_valid, reason = is_valid_translation(texts_batch, translated_list)
            
            if not is_valid:
                print(f"‚ö†Ô∏è Validation Failed: {reason}. Retrying...")
                # ŸÜÿπÿ™ÿ®ÿ±Ÿáÿß ŸÅÿ¥ŸÑÿßŸã ŸàŸÜÿπŸäÿØ ÿßŸÑŸÖÿ≠ÿßŸàŸÑÿ© ÿ£Ÿà ÿßŸÑÿ™ŸÇÿ≥ŸäŸÖ
                continue 

            return [f"{RLE}{text}{PDF}" for text in translated_list]
            
        except Exception as e:
            error_msg = str(e)
            if "429" in error_msg or "Rate limit" in error_msg:
                wait_time = 30 
                if depth > 0: wait_time = 10
                print(f"‚è≥ Rate Limit. Cooling down {wait_time}s...")
                time.sleep(wait_time)
                continue
            else:
                pass
    
    # ÿßÿ≥ÿ™ÿ±ÿßÿ™Ÿäÿ¨Ÿäÿ© ÿßŸÑŸÅÿ¥ŸÑ ÿßŸÑÿ∞ŸÉŸä (Recursive Splitting)
    if len(texts_batch) > 1:
        mid = len(texts_batch) // 2
        if depth == 0: print(f"üîÑ Splitting batch...")
        left = translate_batch(texts_batch[:mid], depth+1)
        right = translate_batch(texts_batch[mid:], depth+1)
        if left and right: return left + right
    
    return None

# ==========================================
# ÿ•ÿØÿßÿ±ÿ© ÿßŸÑŸÖŸÑŸÅÿßÿ™ (Processing & Migration)
# ==========================================

def migrate_legacy_files(folder_path):
    """
    Ÿàÿ∏ŸäŸÅÿ© ÿ•ÿµŸÑÿßÿ≠ Ÿàÿ™ŸÜÿ∏ŸäŸÖ ÿßŸÑŸÖŸÑŸÅÿßÿ™ ÿßŸÑŸÇÿØŸäŸÖÿ© ŸÑÿ™ŸàÿßŸÅŸÇ ÿßŸÑŸÜÿ∏ÿßŸÖ ÿßŸÑÿ¨ÿØŸäÿØ (VLC Ready).
    ÿ™ÿ≠ŸàŸÑ: Name.vtt (Eng) + Name_ar.vtt (Ara)
    ÿ•ŸÑŸâ: Name_en.vtt (Eng) + Name.vtt (Ara)
    """
    print("üßπ Checking for legacy file names to fix...")
    
    # ÿßŸÑÿ®ÿ≠ÿ´ ÿπŸÜ ŸÉŸÑ ÿßŸÑŸÖŸÑŸÅÿßÿ™ ÿßŸÑÿ™Ÿä ÿ™ŸÜÿ™ŸáŸä ÿ®ŸÄ _ar ÿ£Ÿà _gemini_ar
    legacy_patterns = ["*_ar.vtt", "*_ar.srt", "*_gemini_ar.vtt", "*_gemini_ar.srt"]
    found_arabic_files = []
    for pattern in legacy_patterns:
        found_arabic_files.extend(list(folder_path.glob(pattern)))
        
    count = 0
    for ar_file in found_arabic_files:
        # ÿßÿ≥ÿ™ÿÆÿ±ÿßÿ¨ ÿßŸÑÿßÿ≥ŸÖ ÿßŸÑÿ£ÿµŸÑŸä ÿßŸÑŸÖÿ™ŸàŸÇÿπ
        # ŸÖÿ´ÿßŸÑ: video_gemini_ar.vtt -> video.vtt
        # ŸÖÿ´ÿßŸÑ: video_ar.vtt -> video.vtt
        suffix = ar_file.suffix
        stem = ar_file.stem
        
        if "_gemini_ar" in stem:
            base_name = stem.replace("_gemini_ar", "")
        elif "_ar" in stem:
            base_name = stem.replace("_ar", "")
        else:
            continue
            
        original_file_path = ar_file.parent / (base_name + suffix)
        
        # ÿßŸÑÿ≠ÿßŸÑÿ©: ÿßŸÑŸÖŸÑŸÅ ÿßŸÑÿπÿ±ÿ®Ÿä (_ar) ŸÖŸàÿ¨ŸàÿØÿå ŸàÿßŸÑŸÖŸÑŸÅ ÿßŸÑÿ£ÿµŸÑŸä (ÿ®ÿØŸàŸÜ _ar) ŸÖŸàÿ¨ŸàÿØ ÿ£Ÿäÿ∂ÿßŸã
        if original_file_path.exists():
            
            # ÿßŸÑÿ™ÿ≠ŸÇŸÇ: ŸáŸÑ ÿßŸÑŸÖŸÑŸÅ "ÿßŸÑÿ£ÿµŸÑŸä" ŸáŸà ŸÅÿπŸÑÿßŸã ÿ•ŸÜÿ¨ŸÑŸäÿ≤Ÿäÿü (ŸÑÿß Ÿäÿ≠ÿ™ŸàŸä ÿπŸÑŸâ RTL)
            if not is_output_file(original_file_path):
                # ŸÜÿπŸÖ ŸáŸà ÿ•ŸÜÿ¨ŸÑŸäÿ≤Ÿäÿå Ÿäÿ¨ÿ® ÿ•ÿπÿßÿØÿ© ÿ™ÿ≥ŸÖŸäÿ™Ÿá ÿ•ŸÑŸâ _en
                en_new_path = ar_file.parent / (base_name + "_en" + suffix)
                
                try:
                    # 1. ÿ™ÿ∫ŸäŸäÿ± ÿßÿ≥ŸÖ ÿßŸÑÿ•ŸÜÿ¨ŸÑŸäÿ≤Ÿä ÿßŸÑŸÇÿØŸäŸÖ ÿ•ŸÑŸâ _en
                    # (ÿ•ŸÑÿß ÿ•ÿ∞ÿß ŸÉÿßŸÜ _en ŸÖŸàÿ¨ŸàÿØÿßŸã ŸÖÿ≥ÿ®ŸÇÿßŸãÿå ÿ≠ŸäŸÜŸáÿß ŸÜÿ≠ÿ∞ŸÅŸá ÿ£Ÿà ŸÜÿ™ÿ¨ÿßŸàÿ≤)
                    if not en_new_path.exists():
                        original_file_path.rename(en_new_path)
                        print(f"üì¶ Migrating: {original_file_path.name} -> {en_new_path.name}")
                    else:
                        # ÿ•ÿ∞ÿß ŸÉÿßŸÜ _en ŸÖŸàÿ¨ŸàÿØÿßŸãÿå ÿ∫ÿßŸÑÿ®ÿßŸã ÿßŸÑÿ£ÿµŸÑ ŸáŸà ŸÜÿ≥ÿÆÿ© ŸÖŸÉÿ±ÿ±ÿ©ÿå ŸäŸÖŸÉŸÜ ÿ≠ÿ∞ŸÅŸá ÿ®ÿ£ŸÖÿßŸÜ
                        # ŸÑŸÉŸÜ ŸÑŸÑÿ£ŸÖÿßŸÜ ÿ≥ŸÜÿ®ŸÇŸäŸá ŸàŸÜÿ∫Ÿäÿ± ÿßÿ≥ŸÖŸá ŸÑŸÄ backup
                        # original_file_path.rename(ar_file.parent / (base_name + "_backup" + suffix))
                        pass

                    # 2. ÿ™ÿ∫ŸäŸäÿ± ÿßÿ≥ŸÖ ÿßŸÑÿπÿ±ÿ®Ÿä (_ar) ŸÑŸäÿ£ÿÆÿ∞ ŸÖŸÉÿßŸÜ ÿßŸÑÿ£ÿµŸÑŸä
                    # ÿ™ÿ£ŸÉÿØ ÿ£ŸÜ ÿßŸÑŸÖŸÉÿßŸÜ ÿ£ÿµÿ®ÿ≠ ŸÅÿßÿ±ÿ∫ÿßŸã ÿßŸÑÿ¢ŸÜ
                    if not original_file_path.exists():
                        ar_file.rename(original_file_path)
                        print(f"‚úÖ Fixed Arabic: {ar_file.name} -> {original_file_path.name}")
                        count += 1
                except Exception as e:
                    print(f"‚ùå Error migrating {base_name}: {e}")

    if count > 0:
        print(f"üéâ Migrated {count} files to VLC-Ready format.\n")
    else:
        print("üëç No legacy files needed migration.\n")


def process_file_logic(source_file_path):
    stem = source_file_path.stem
    suffix = source_file_path.suffix
    
    # 1. ÿ™ÿ≠ÿØŸäÿØ ÿßŸÑŸÖŸÑŸÅÿßÿ™
    if stem.lower().endswith(('_en', ' en', '_eng')):
        actual_source = source_file_path
        target_name = re.sub(r'(_en| en|_eng)$', '', stem, flags=re.IGNORECASE) + suffix
        output_path = source_file_path.parent / target_name
    else:
        # ÿ•ÿ∞ÿß ŸÑŸÖ ŸäŸÉŸÜ ŸäŸÜÿ™ŸáŸä ÿ®ŸÄ _enÿå ŸÜŸÇŸàŸÖ ÿ®ÿ™ÿ∫ŸäŸäÿ± ÿßÿ≥ŸÖŸá ÿ£ŸàŸÑÿßŸã
        new_source_name = f"{stem}_en{suffix}"
        new_source_path = source_file_path.parent / new_source_name
        
        print(f"üì¶ Renaming source: {source_file_path.name} -> {new_source_name}")
        try:
            source_file_path.rename(new_source_path)
            actual_source = new_source_path
            output_path = source_file_path 
        except OSError as e:
            print(f"‚ùå Could not rename file: {e}")
            return False

    # 2. ÿßŸÑÿ™ÿ≠ŸÇŸÇ
    if output_path.exists():
        if is_output_file(output_path):
            print(f"‚è≠Ô∏è  Skipped: {output_path.name} (Already translated).")
            return True
        else:
            print(f"‚ö†Ô∏è Warning: {output_path.name} exists but isn't Arabic. Overwriting...")

    # 3. ÿßŸÑŸÖÿπÿßŸÑÿ¨ÿ©
    print(f"\nüìÑ Processing: {actual_source.name} -> {output_path.name}")
    
    is_vtt = suffix.lower() == '.vtt'
    if is_vtt:
        try: subs = list(webvtt.read(actual_source))
        except: return False
    else:
        try:
            subs = pysrt.open(str(file_path), encoding='utf-8')
        except:
             print(f"‚ùå Error reading SRT file: {file_path.name}")
             return False

    all_texts = [sub.text for sub in subs]
    translated_texts = []
    BATCH_SIZE = 15
    
    pbar = tqdm(range(0, len(all_texts), BATCH_SIZE), desc="üåê Translating", leave=False)
    
    for i in pbar:
        batch = all_texts[i : i + BATCH_SIZE]
        translated_batch = translate_batch(batch)
        
        if translated_batch is None:
            pbar.close()
            print(f"‚ö†Ô∏è Failed to translate {actual_source.name}")
            return False 
            
        translated_texts.extend(translated_batch)



    if is_vtt:
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write("WEBVTT\n\nSTYLE\n::cue {\n  direction: rtl;\n  text-align: right;\n}\n\n")
            for i, sub in enumerate(subs):
                txt = translated_texts[i] if i < len(translated_texts) else ""
                f.write(f"{sub.start} --> {sub.end} align:right\n{txt}\n\n")
    else:
        for i, sub in enumerate(subs):
            sub.text = translated_texts[i] if i < len(translated_texts) else ""
        subs.save(str(output_path), encoding='utf-8')

    print(f"‚úÖ Success: Generated {output_path.name}")
    return True

def main():
    if not API_KEY or API_KEY.startswith("sk-or-v1-xx"):
        print("‚ùå Error: Missing API Key.")
        return

    folder_input = input("üìÅ Enter folder path: ").strip().strip('"')
    folder_path = Path(folder_input)

    if not folder_path.is_dir():
        print("‚ùå Invalid directory.")
        return

    # üî• ÿÆÿ∑Ÿàÿ© 1: ÿ•ÿµŸÑÿßÿ≠ ÿßŸÑŸÖŸÑŸÅÿßÿ™ ÿßŸÑŸÇÿØŸäŸÖÿ© ÿ£ŸàŸÑÿßŸã
    migrate_legacy_files(folder_path)

    # üî• ÿÆÿ∑Ÿàÿ© 2: ÿ¨ŸÖÿπ ÿßŸÑŸÖŸÑŸÅÿßÿ™ ÿßŸÑŸÖÿ™ÿ®ŸÇŸäÿ© ŸÑŸÑŸÖÿπÿßŸÑÿ¨ÿ©
    all_files = list(folder_path.glob("*.vtt")) + list(folder_path.glob("*.srt"))
    
    if not all_files:
        print("‚ö†Ô∏è No files found.")
        return

    files_to_process = []
    
    print("üîç Scanning files...")
    for file in all_files:
        # ÿ•ÿ∞ÿß ŸÉÿßŸÜ ŸÖŸÑŸÅ ŸÜÿßÿ™ÿ¨ (ÿπÿ±ÿ®Ÿä)ÿå ŸÜÿ™ÿ¨ÿßŸáŸÑŸá
        if is_output_file(file):
            continue
            
        # ÿ•ÿ∞ÿß ŸÉÿßŸÜ ŸÖŸÑŸÅ _enÿå ŸáŸà ŸÖÿµÿØÿ± ŸÖÿ≠ÿ™ŸÖŸÑ
        if file.stem.lower().endswith(('_en', ' en')):
             files_to_process.append(file)
             continue
             
        # ÿ•ÿ∞ÿß ŸÉÿßŸÜ ŸÖŸÑŸÅÿßŸã ÿπÿßÿØŸäÿßŸã (ŸÑŸäÿ≥ ÿπÿ±ÿ®ŸäÿßŸã ŸàŸÑŸäÿ≥ _en)ÿå ŸÅŸáŸà ŸÖÿµÿØÿ± ÿ¨ÿØŸäÿØ Ÿäÿ≠ÿ™ÿßÿ¨ ÿ•ÿπÿßÿØÿ© ÿ™ÿ≥ŸÖŸäÿ© Ÿàÿ™ÿ±ÿ¨ŸÖÿ©
        files_to_process.append(file)

    print(f"üìã Found {len(files_to_process)} files to translate.\n")

    for i, file in enumerate(files_to_process, 1):
        print(f"[{i}/{len(files_to_process)}]", end=" ")
        success = process_file_logic(file)
        
        if not success:
            print("üîª Failed.")
            time.sleep(1)

    print("\nüéâ All operations completed.")

if __name__ == "__main__":
    main()